{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "be1749ea",
      "metadata": {
        "id": "be1749ea"
      },
      "source": [
        "# GrainBot: A toolkit featured Segmentation, Measurement, and Statistic analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading your Google drive and importing code from Github"
      ],
      "metadata": {
        "id": "-_cZ-Fk3dyox"
      },
      "id": "-_cZ-Fk3dyox"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "path=\"/content/drive/MyDrive/GrainBot_validation\"\n",
        "os.chdir(path)"
      ],
      "metadata": {
        "id": "8kHxcDPocEXN",
        "outputId": "8b61d5d2-7525-469c-cb6d-668367023691",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "8kHxcDPocEXN",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/yalan-z/GrainBot-V2.git"
      ],
      "metadata": {
        "collapsed": true,
        "id": "F79-HBv-eFL-",
        "outputId": "b11fae36-9fec-4614-981e-7cc45de27f15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "F79-HBv-eFL-",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'GrainBot-V2' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "5b56fd99",
      "metadata": {
        "id": "5b56fd99"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/GrainBot_validation/GrainBot-V2')\n",
        "sys.path.append('/content/drive/MyDrive/GrainBot_validation/GrainBot-V2/GBGchar')\n",
        "from importlib.machinery import SourceFileLoader\n",
        "import postprocess_special as process\n",
        "import mask_operation as mask_op\n",
        "import AFMOpr\n",
        "import MaskOpr\n",
        "import GrainOpr\n",
        "import StatisticM\n",
        "##Install the following packages using pip first\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "segment=SourceFileLoader(\"ImageSeg\", \"/content/drive/MyDrive/GrainBot_validation/GrainBot-V2/ImageSeg.py\").load_module()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a98c9aa",
      "metadata": {
        "id": "6a98c9aa"
      },
      "source": [
        "## Loading SPM images and run segmentation process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "1eee2a4b",
      "metadata": {
        "id": "1eee2a4b",
        "outputId": "707a120f-4276-4fcb-b9a5-f575c4ea6228",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/GrainBot_validation/GrainBot-V2/ImageSeg.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  unet.load_state_dict(torch.load(self.path, map_location=torch.device('cpu')))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "successfully segmented\n"
          ]
        }
      ],
      "source": [
        "##Make sure there are only .png images need segmentation in this path\n",
        "##Remove all the outputs before rerunning the code\n",
        "\n",
        "imgpath='../GrainBot_validation/dataset'\n",
        "wei_path='/content/drive/MyDrive/GrainBot_validation/GrainBot-V2/params/unet.pth'\n",
        "Dataset=segment.validation(wei_path)\n",
        "Dataset.valid(imgpath)\n",
        "##Successfully segmented images could be found in the same path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5957843",
      "metadata": {
        "id": "d5957843"
      },
      "source": [
        "## Measuring microstructural parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "b89620a1",
      "metadata": {
        "id": "b89620a1"
      },
      "outputs": [],
      "source": [
        "\n",
        "##Input scale information of SPM images (unit:nm)\n",
        "z_min=-40\n",
        "z_max=40\n",
        "img_width=4000\n",
        "for n in Dataset.filenames:\n",
        "    pddata=pd.DataFrame({'gsa':[1],'cve':[1],'rel_cve':[1],\\\n",
        "                     'rel_h':[1],'cca':[1],'rel_d':[1],'mean_angle':[1]})\n",
        "    pd_angle=pd.DataFrame({'grain number':[1],'gsa':[1]})\n",
        "    afm_img=cv2.imread(imgpath+'/'+n)\n",
        "    mask_img=cv2.imread(imgpath+'/'+'seg_'+n)\n",
        "    act_img=AFMOpr.AFMimg(afm_img,mask_img,z_min,z_max,img_width)\n",
        "    act_img.MorphOpr()\n",
        "    act_img.Labeling()\n",
        "    for i in range(1,act_img.numx):\n",
        "\n",
        "        grain=GrainOpr.Grains(i)\n",
        "        grain.grainmask(act_img.labelimg,act_img.afm)\n",
        "        grain.maskdil(act_img.afm)\n",
        "        grain.maskregain(act_img.afm)\n",
        "        grain.maskero(act_img.afm)\n",
        "        grain.areacal()\n",
        "        volcoe=(act_img.lmax-act_img.lmin)/255*act_img.pixelsize*act_img.pixelsize\n",
        "        areacoe=act_img.pixelsize*act_img.pixelsize\n",
        "        if grain.area>50:\n",
        "            grain.voidcal(5)##The step of sections used for CCA or CVE calculation\n",
        "            grain.anglecal(act_img.realdimg,act_img.pixelsize)\n",
        "\n",
        "            realarea=grain.area*areacoe\n",
        "            data_i=pd.DataFrame({'gsa':[realarea],'cve':[grain.vb*volcoe],\\\n",
        "                                 'rel_cve':[grain.rel_vb*volcoe],'rel_h':[grain.vb*volcoe/realarea],\\\n",
        "                                 'cca':[grain.vd*volcoe],'rel_d':[grain.vd*volcoe/realarea],\\\n",
        "                                 'mean_angle':[max(grain.angles)]},index=[i])\n",
        "            for j in range(0,len(grain.angles)):\n",
        "                angle_j=pd.DataFrame({'grain number':[i],'gsa':[grain.angles[j]]})\n",
        "                pd_angle=pd.concat([pd_angle,angle_j])\n",
        "\n",
        "            pddata=pd.concat([pddata,data_i])\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "    pddata.to_csv(imgpath+'/'+n+'.csv')\n",
        "    pd_angle.to_csv(imgpath+'/angles_'+n+'.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58149fb6",
      "metadata": {
        "id": "58149fb6"
      },
      "source": [
        "## Statisitcal analysis on microstructural parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d517208",
      "metadata": {
        "id": "3d517208"
      },
      "outputs": [],
      "source": [
        "\n",
        "Angledata=StatisticM.StatisticAng(imgpath+'//'+'allangles_A3.0_00007.csv')\n",
        "CCAdata=StatisticM.StatisticCCA(imgpath+'//'+'A3.0_00002.csv')\n",
        "CVEdata=StatisticM.StatisticCVE(imgpath+'//'+'A3.0_00002.csv')\n",
        "GSAdata=StatisticM.StatisticGSA(imgpath+'//'+'A3.0_00002.csv')\n",
        "figure = plt.figure(figsize=(12,10),edgecolor=\"black\",frameon=True)\n",
        "plt.tight_layout()\n",
        "ax=plt.subplot(2,2,1)\n",
        "Angledata.histplot(1,40)\n",
        "plt.text(0.55, 0.7, 'mean: ' + '%.2f' % Angledata.mu, transform=ax.transAxes, size=18)\n",
        "plt.text(0.55, 0.6, 'variance: ' + '%.2f' % Angledata.sigma, transform=ax.transAxes,size=18)\n",
        "plt.subplot(2,2,2)\n",
        "CCAdata.histplot()\n",
        "plt.subplot(2,2,3)\n",
        "CVEdata.histplot()\n",
        "plt.subplot(2,2,4)\n",
        "GSAdata.histplot()\n",
        "plt.tight_layout(pad=2,w_pad=3)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}